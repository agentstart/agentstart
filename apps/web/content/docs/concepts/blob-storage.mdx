---
title: Blob Storage
description: Configure file uploads and attachments for AgentStart deployments
---

AgentStart ships with first-class blob storage support so your agents can accept file uploads, persist normalized metadata, and reuse attachments across tools, memory, and UI layers.

<Callout>
  Blob storage is optional. If you skip configuration the `config.get` procedure returns `{ blob: { enabled: false } }` and file uploads are disabled automatically.
</Callout>

## Enabling Blob Storage

Configure blob storage using adapter factories when you call `agentStart`. The adapter pattern provides a clean, type-safe interface for different storage providers.

```ts title="lib/agent.ts"
import { agentStart } from "agentstart";
import { vercelBlobAdapter } from "agentstart/blob/vercel";

export const start = agentStart({
  agent,
  memory,
  blob: vercelBlobAdapter({
    token: process.env.BLOB_READ_WRITE_TOKEN!,
    constraints: {
      maxFileSize: 10 * 1024 * 1024, // 10 MB
      allowedMimeTypes: [
        "image/jpeg",
        "image/png",
        "application/pdf",
        "text/plain",
        "text/markdown",
      ],
      maxFiles: 5,
      uploadTiming: "onSubmit", // or "immediate"
    },
  }),
});
```

Every request handler can read the resolved adapter through the ORPC context, so tools can stream upload metadata back to your workflows.

## Provider Configuration

AgentStart includes adapter factories for Vercel Blob, AWS S3, and Cloudflare R2. Each adapter exposes the same API surface (`put`, `head`, `list`, multipart helpers) so downstream consumers can stay provider-agnostic.

### Vercel Blob

```ts title="lib/agent.ts"
import { vercelBlobAdapter } from "agentstart/blob/vercel";

export const start = agentStart({
  agent,
  memory,
  blob: vercelBlobAdapter({
    token: process.env.BLOB_READ_WRITE_TOKEN!,
    constraints: {
      maxFileSize: 10 * 1024 * 1024, // 10 MB
      allowedMimeTypes: ["image/*", "application/pdf"],
      maxFiles: 5,
      uploadTiming: "onSubmit",
    },
  }),
});
```

Environment variables:

```bash title=".env"
BLOB_READ_WRITE_TOKEN=vercel_blob_rw_...
```

### AWS S3

```ts title="lib/agent.ts"
import { s3BlobAdapter } from "agentstart/blob/s3";

export const start = agentStart({
  agent,
  memory,
  blob: s3BlobAdapter({
    credentials: {
      accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
    },
    bucket: process.env.AWS_S3_BUCKET!,
    region: "us-east-1",
    endpoint: process.env.AWS_S3_ENDPOINT, // optional override
    constraints: {
      maxFileSize: 50 * 1024 * 1024, // 50 MB
      allowedMimeTypes: ["image/*", "application/pdf"],
    },
  }),
});
```

Environment variables:

```bash title=".env"
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
AWS_S3_BUCKET=my-agent-uploads
AWS_S3_ENDPOINT=https://s3.us-east-1.amazonaws.com # optional
```

### Cloudflare R2

```ts title="lib/agent.ts"
import { r2BlobAdapter } from "agentstart/blob/s3";

export const start = agentStart({
  agent,
  memory,
  blob: r2BlobAdapter({
    credentials: {
      accessKeyId: process.env.R2_ACCESS_KEY_ID!,
      secretAccessKey: process.env.R2_SECRET_ACCESS_KEY!,
    },
    bucket: process.env.R2_BUCKET_NAME!,
    accountId: process.env.R2_ACCOUNT_ID!,
    endpoint: `https://${process.env.R2_ACCOUNT_ID}.r2.cloudflarestorage.com`,
    constraints: {
      maxFileSize: 100 * 1024 * 1024, // 100 MB
      allowedMimeTypes: ["image/*", "application/pdf", "text/plain"],
      uploadTiming: "immediate",
    },
  }),
});
```

Environment variables:

```bash title=".env"
R2_ACCESS_KEY_ID=...
R2_SECRET_ACCESS_KEY=...
R2_BUCKET_NAME=my-r2-bucket
R2_ACCOUNT_ID=...
```

## Client Attachments

Use the `useBlobFiles` hook from `agentstart/client` to validate and upload files before they reach your tools.

```tsx title="components/attachment-input.tsx"
"use client";

import type { ChangeEvent } from "react";
import { useBlobFiles } from "agentstart/client";
import { client } from "@/lib/agent-client";

export function AttachmentInput() {
  const { files, setFiles, processFiles, clearFiles, isUploading, uploadTiming } =
    useBlobFiles();

  const handleFileChange = (event: ChangeEvent<HTMLInputElement>) => {
    if (!event.target.files) return;
    setFiles(event.target.files);
  };

  const handleSubmit = async () => {
    const processed = await processFiles();
    console.log("Ready to send:", processed);
    clearFiles();
  };

  return (
    <div className="grid gap-2">
      <input type="file" multiple onChange={handleFileChange} />
      <div className="text-xs text-muted-foreground">
        Upload timing: {uploadTiming} — {files.length} file(s) selected
      </div>
      <button type="button" onClick={handleSubmit} disabled={isUploading}>
        {isUploading ? "Uploading…" : "Attach"}
      </button>
    </div>
  );
}
```

The hook normalizes browser `File` objects and `FileUIPart` blobs, enforces constraints locally, surfaces upload progress, and merges the resolved metadata back into your message payload.

## Server-Side Validation

The `blob.upload` ORPC procedure performs a second layer of validation—rejecting oversized files, disallowed MIME types, or requests that exceed `maxFiles`. Make sure you set realistic limits to prevent abuse.

## Troubleshooting

- `config.get` returns `{ blob: { enabled: false } }`: the `blob` option was omitted or misconfigured. Verify environment variables and restart the server.
- Upload requests return `403` or `SignatureDoesNotMatch`: double-check provider credentials and bucket permissions.
- Large uploads stall: switch to `uploadTiming: "immediate"` so files upload while the user composes a message, then confirm the provider supports multipart uploads.

## Related Guides

<Cards>
  <Card title="Prompt Input Component" href="/docs/components/prompt-input" />
  <Card title="Next.js Integration" href="/docs/integrations/next" />
  <Card title="Database Concepts" href="/docs/concepts/database" />
</Cards>
